<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Yi-Chao  Chen | Handwriting Recognition System based on Vibration Signal</title>
    <meta name="author" content="Yi-Chao  Chen" />
    <meta name="description" content="We presented a novel handwriting recognition system based on vibration signals detected by the built-in accelerometer of smart phones." />
    <meta name="keywords" content="academic-website, portfolio-website, computer-science, mobile-computing, cyber-physical-system" />


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous" />

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light" />

    <!-- Styles -->
    
    <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>⚛️</text></svg>">
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="https://yichao0319.github.io/projects/2020_vibwriter/">
    
    <!-- Dark Mode -->
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="https://yichao0319.github.io/"><img src="/assets/img/logo-lab2.png" width="300"></a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">About</a>
              </li>
              

              <!-- Other pages -->
              <!---->
              <li class="nav-item ">
                <a class="nav-link" href="/publications/">Publications</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/projects/">Projects</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/courses/">Teaching</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/patents/">Patent</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/awards/">Awards</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/internal/">Internal</a>
              </li>
            </ul>
          </div>
        </div>
      </nav>
    </header>

    <!-- Content -->
    <div class="container mt-5">
      <!-- page.html -->
<div class="post">

  <h2 class="post-title" style="font-weight: bold; text-align: center; ">Handwriting Recognition System based on Vibration Signal</h2>

  
  
  
  
  
  <div style="font-weight: bold; text-align: center; font-size: 16px">
  <!-- check affiliations -->
    
    
    

    
    <!-- END: check affiliations -->

    Dian Ding<sup> 1</sup>
    ,
    
  <!-- check affiliations -->
    
    
    

    
    <!-- END: check affiliations -->

    Lanqing Yang<sup> 1</sup>
    ,
    
  <!-- check affiliations -->
    
    
    

    
    <!-- END: check affiliations -->

    Yi-Chao Chen<sup> 1</sup>
    ,
    
  <!-- check affiliations -->
    
    
    

    
    <!-- END: check affiliations -->

    Guangtao Xue<sup> 1</sup>
    
    
  
  </div>
  <div style="font-weight: normal; text-align: center; font-size: 16px">
  Shanghai Jiao Tong University<sup> 1</sup>
    
  
  </div>

  <article style="text-align: justify;">
    <h2 id="abstract">Abstract</h2>

<p>The efficiency of human-computer interaction is greatly hindered by the small size of the touchscreens on mobile devices, such as smart phones and watches. This has prompted widespread interest in handwriting recognition systems, which can be divided into active and passive systems. Active systems require additional hardware devices to perceive movements of handwriting or the tracking accuracy is not adequate for handwriting recognition. Passive methods use the acoustic signal of pen rubbing and are susceptible to environmental noise (above 60dB). This paper presents a novel handwriting recognition system based on vibration signals detected by the built-in accelerometer of smart phones. <em>VibWriter</em> is highly resistant to interference since the normal environmental noise will not cause the vibration of the accelerometer. Extensive experiments demonstrated the efficacy of the system in terms of accuracy in letter recognition (76.15%) and word recognition (88.14%) when dealing with words of various lengths written by various users in a variety of writing positions under a variety of environmental conditions.</p>

<hr>

<h2 id="background">Background</h2>

<p><em>VibWriter</em> uses the built-in accelerometer of a Samsung S7 to detect vibration signals generated by the desk when in contact with a pen. The accelerometer of smart phone can achieve the sampling rate of approximately 500Hz [1], and even a small strokes of 0.1s can generate 50 samples. Therefore, we try to recognize different handwriting letters with the vibration signal. As shown in Fig. 1(a), when writing the letters “C”, “X”, and “Z”, the exceedingly weak amplitude of the vibration signals make it difficult to differentiate between the three letters directly. Besides, different letters comprise different numbers of strokes, as indicated by the spectrum in which the letter “Z” comprises three strokes, the letter “X” comprises two , and the letter “C” comprises only one stroke (see Fig.1(b)).</p>

<div class="row justify-content-sm-center">
    <div class="col-sm-4 mt-3 mt-md-0">
        <figure>

  <picture>
    <source media="(max-width: 480px)" srcset="/assets/img/project-vibwriter-letters_accel-480.webp"></source>
    <source media="(max-width: 800px)" srcset="/assets/img/project-vibwriter-letters_accel-800.webp"></source>
    <source media="(max-width: 1400px)" srcset="/assets/img/project-vibwriter-letters_accel-1400.webp"></source>
    <!-- Fallback to the original file -->
    <img class="img-fluid rounded z-depth-1" src="/assets/img/project-vibwriter-letters_accel.png">

  </picture>

</figure>

    </div>
    <div class="col-sm-4 mt-3 mt-md-0">
        <figure>

  <picture>
    <source media="(max-width: 480px)" srcset="/assets/img/project-vibwriter-letters-480.webp"></source>
    <source media="(max-width: 800px)" srcset="/assets/img/project-vibwriter-letters-800.webp"></source>
    <source media="(max-width: 1400px)" srcset="/assets/img/project-vibwriter-letters-1400.webp"></source>
    <!-- Fallback to the original file -->
    <img class="img-fluid rounded z-depth-1" src="/assets/img/project-vibwriter-letters.png">

  </picture>

</figure>

    </div>
</div>
<div class="caption">
  Fig. 1 Preliminary experiments with Samsung S7: vibration signal (a) and spectrum (b) generated by writing the letters “C”, “X” and “Z”.
</div>

<hr>

<h2 id="system">System</h2>

<p><em>VibWriter</em> comprises three modules: letter segmentation, letter recognition, and word suggestion. Vibration signal detected by the built-in accelerometer is first sent to the letter segmentation module to be divided into discrete segments. The letter recognition module identifies the different segments. Finally, the word suggestion module combines the letters into words.</p>

<div class="row justify-content-sm-center">
    <div class="col-sm-9 mt-3 mt-md-0">
        <figure>

  <picture>
    <source media="(max-width: 480px)" srcset="/assets/img/project-vibwriter-system-480.webp"></source>
    <source media="(max-width: 800px)" srcset="/assets/img/project-vibwriter-system-800.webp"></source>
    <source media="(max-width: 1400px)" srcset="/assets/img/project-vibwriter-system-1400.webp"></source>
    <!-- Fallback to the original file -->
    <img class="img-fluid rounded z-depth-1" src="/assets/img/project-vibwriter-system.png">

  </picture>

</figure>

    </div>
</div>
<div class="caption">
  Fig. 2 System overview of VibWriter.
</div>

<h3 id="letter-segmentation">Letter Segmentation</h3>

<p>Obtaining the highest sampling rate from the built-in accelerometer precludes the stable sampling rate of raw data [1]. In most situations, more than half of the vibration signals are missing, such that the actual number of samples collected per second is roughly 490. The accuracy of timestamps is 1ms. Therefore, we upsampling the raw data to 1000Hz by spline interpolation.</p>

<p>Generally, the tap of a pen on the desk surface produces a distinctive vibration pattern indicating the beginning of writing. However, in some situations where the user seeks to write quietly, such as a meeting room, the writing process begins with a swipe. This situation makes it difficult to identify the start of writing. The signal produced by a tap presents an abrupt change in amplitude, whereas the amplitude of the signal produced by a swiping motion grows gradually. The common approach to segmentation often fails to identify vibration signals that begin with a swipe [2], [3]. We calculate the mean value of the vibration signal S(t) with the sliding window tw = 100ms.</p>

<p>Letter detection is based largely on three time thresholds T1, T2 and T3, and three amplitude thresholds A1, A2 and A3. T1 and T2 indicate the minimum and maximum lengths of the letters, whereas T3 indicates the time interval between words. A1 and A2 indicate the maximum and minimum absolute values of M(t), whereas A3 indicates the minimum absolute value of interference. We use the time threshold to constrain the signal length of letters and words, and the amplitude threshold to judge the begin and end of the signal.</p>

<p>Peak selection is based on the amplitude threshold, where the start threshold is M_{start} = \(0.2 × A1 + 0.8 × A2\) and the end threshold is \(M_{end} = 0.1 × A1 + 0.9 × A2\).</p>

<h3 id="letter-recognition">Letter Recognition</h3>

<p>We adopt Short-time Fourier Transform (STFT) to generate features in the frequency domain. We develop a dynamic denoising algorithm, which identifies noise based on a reference signal collected during idle periods. We begin by establishing a noise sample \(S_noise = [s_1, s_2, ..., s_l]\), and then update the sample as:</p>

\[\hat{S}_{noise} = \frac{1}{N}\sum_{i=1}^{N}S_{noise_{i}}\]

<p>where l indicates the length of the noise sample according to different handwriting segments. S_noise preserves the noise signal between letters and words, and N represents the number of samples in S_noise. Then, we can denoise the signal with the spectrum subtraction:</p>

\[||Y(k)||^2 = ||S_{signal}(k)||^2 + ||\hat{S}_{noise}(k)||^2\]

<p>Convolutional neural network (CNN) have proven highly effective in spectrum classification [2], [3]. The spectral width of vibration signals is far narrower than acoustic signals. Therefore, the module have to extract handwriting features at various scales, (e.g., single taps, single strokes, and entire letters). We achieved handwriting recognition using the Xception model and Focal Loss.</p>

<h3 id="word-suggestion">Word Suggestion</h3>

<p>We notice the fact that users often write a word rather than a single letter. Therefore, we develop a word suggestion algorithm to enhance handwriting recognition performance at the word level. We utilized the N-gram algorithm [4] and edit distance to implement word suggestion of different lengths.</p>

<hr>

<h2 id="evaluation">Evaluation</h2>

<p>VibWriter is implemented on a Samsung S7 and a MacBook Pro (Intel Core i9 CPU@2.3GHz and 16GB RAM) is implemented as the server. Based on the built-in accelerometer, we can achieve a sampling rate of about 490Hz. We use a third-party application AccDataRec for diaplay.</p>

<div class="row justify-content-sm-center">
    <div class="col-sm-8 mt-3 mt-md-0">
        <figure>

  <picture>
    <source media="(max-width: 480px)" srcset="/assets/img/project-vibwriter-cover-480.webp"></source>
    <source media="(max-width: 800px)" srcset="/assets/img/project-vibwriter-cover-800.webp"></source>
    <source media="(max-width: 1400px)" srcset="/assets/img/project-vibwriter-cover-1400.webp"></source>
    <!-- Fallback to the original file -->
    <img class="img-fluid rounded z-depth-1" src="/assets/img/project-vibwriter-cover.png">

  </picture>

</figure>

    </div>
</div>
<div class="caption">
  Fig. 3 Evaluational setup.
</div>

<p>We use the top-1 output of the network as the recognition result. As shown in Fig. 4, the average accuracy in letter recognition is 75.69%. Analysis of misclassification reveals that around 20% of the letters ”K” and ”N” are misidentified as ”R” and ”V”, respectively. Clearly, a word suggestion algorithm is required to achieve reasonable recognition performance.</p>

<div class="row justify-content-sm-center">
    <div class="col-sm-5 mt-3 mt-md-0">
        <figure>

  <picture>
    <source media="(max-width: 480px)" srcset="/assets/img/project-vibwriter-confusion_matrix-480.webp"></source>
    <source media="(max-width: 800px)" srcset="/assets/img/project-vibwriter-confusion_matrix-800.webp"></source>
    <source media="(max-width: 1400px)" srcset="/assets/img/project-vibwriter-confusion_matrix-1400.webp"></source>
    <!-- Fallback to the original file -->
    <img class="img-fluid rounded z-depth-1" src="/assets/img/project-vibwriter-confusion_matrix.png">

  </picture>

</figure>

    </div>
</div>
<div class="caption">
  Fig. 4 Confusion matrix of letter recognition.
</div>

<p>The performance of the VibWriter system using the N-gram algorithm for short words and the edit distance algorithms for longer words is verified by count- ing the number of correct words suggestions. The proposed algorithms achieve overall accuracy of 88.14% for words of various lengths.</p>

<hr>

<h2 id="reference">Reference</h2>
<p>[1] Z. Ba, T. Zheng, X. Zhang, Z. Qin, B. Li, X. Liu, and K. Ren, “Learning-based practical smartphone eavesdropping with built-in accelerometer,” 01 2020.</p>

<p>[2] H. Yin, A. Zhou, G. Su, B. Chen, L. Liu, and H. Ma, “Learning to recognize handwriting input with acoustic features,” Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., vol. 4, no. 2, Jun. 2020.</p>

<p>[3] H. Du, P. Li, H. Zhou, W. Gong, G. Luo, and P. Yang, “Wordrecorder: Accurate acoustic-based handwriting recognition using deep learning,” in IEEE INFOCOM 2018 - IEEE Conference on Computer Communi- cations, 2018, pp. 1448–1456.</p>

<p>[4] P. Nather, “N-gram based text categorization,” 2005.</p>

<hr>

<h2 id="publication">Publication</h2>

<div hidden="">
<a class="citation" href="#ding-secon21">Dian Ding et al., “VibWriter: Handwriting Recognition System Based on Vibration Signal,” in <i>IEEE International Conference on Sensing, Communication, and Networking (SECON)</i> (IEEE, 0AD), 1–9, https://doi.org/10.1109/SECON52354.2021.9491615.</a>
</div>


  </article>

</div>

<ol class="bibliography"><li>
<style>
.badge {
  display: inline-block;
  color: #FFFFFF;
  background-color: #9e9e9e;
  min-width: 10px;
  padding: 3px 6px;
  font-size: 12px;
  font-weight: normal;
  line-height: 1;
  text-align: center;
  white-space: nowrap;
  vertical-align: middle;
  border-radius: 2px;
  margin-right: 2px;
  &:hover {
    background-color: #2698BA;
  }
}
.special {
  font-weight: bolder;
  color: #B71C1C;
}
</style>

<!-- Author -->Dian Ding, Lanqing Yang, 
        <em>Yi-Chao Chen</em>, and Guangtao Xue.
<!-- Title -->
<b>
  <a href="https://www.cs.sjtu.edu.cn/~yichao/assets/publications/secon21_ding.pdf" target="_blank" rel="noopener noreferrer">VibWriter: Handwriting Recognition System based on Vibration Signal</a>

</b>.
<!-- Book Title -->
IEEE <b> SECON </b> 2021.
<!-- IEEE International Conference on Sensing, Communication, and Networking (SECON) 2021. -->

  <br>

  <a href="https://www.cs.sjtu.edu.cn/~yichao/assets/publications/secon21_ding.pptx" class="badge" role="button" target="_blank" rel="noopener noreferrer">Slides</a>
</li></ol>

    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        © Copyright 2023 Yi-Chao  Chen. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>.

      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.2/dist/umd/popper.min.js" integrity="sha256-l/1pMF/+J4TThfgARS6KwWrk/egwuVvhRzfLAMQ6Ds4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.min.js" integrity="sha256-SyTu6CwrfOhaznYZPoolVw2rxoY7lKYKQvqbtqN93HI=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
  <script src="/assets/js/zoom.js"></script><!-- Load Common JS -->
  <script src="/assets/js/common.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    
  </body>
</html>

